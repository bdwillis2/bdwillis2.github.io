---
title: "Milestone 3"
author: Berkeley D. Willis
date: 2020-09-24
output: pdf_document
---

```{r echo=FALSE, cache=FALSE, results=FALSE, warning=FALSE, comment=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(data.table)
```

First the data needs to be loaded, and some basic sampling and summarization of the data would be helpful. It can help identify what could be cleaned, as well as give an idea of what data is available, record counts, and even possibly give an idea of what relationship may exist. Of course after the data cleaning operations this will become more obvious.

```{r load_data}
# Now load the data that we want
hf_records_dt = fread("data/heart_failure_clinical_records_dataset.csv")

hf_records_raw_dt = hf_records_dt

hf_records_dt %>% head

# Let's start to see some of the possible data issues such as large
# numbers of NA's
hf_records_dt %>% summary
```

What can be observed here is that the data is pretty clean with no major issues like missing data. However, some of the data types of the values though not ideal for giving a good view of the data. Some of these could be converted to integers and Boolean in order to make the data more clear on the summary and sampling, like a boolean as an indicator for diabetes isn't wrong to be 0/1 but will look simpler in the summary view if converted to a boolean. As well a few numerics like age, just because how R read the file, would look simpler and vizualize better as a non-continuous value.


So the next steps will be to make what will be helpful conversions.

```{r clean_cols}
# First convert those that are best to be used as booleans
hf_records_dt$anaemia = as.logical(hf_records_dt$anaemia)
hf_records_dt$diabetes = as.logical(hf_records_dt$diabetes)
hf_records_dt$high_blood_pressure = as.logical(hf_records_dt$high_blood_pressure)
hf_records_dt$smoking = as.logical(hf_records_dt$smoking)
hf_records_dt$DEATH_EVENT = as.logical(hf_records_dt$DEATH_EVENT)

# Sex currently represented as a number, won't be consider a classification so
# we'll change it to a factor
hf_records_dt$sex = as.factor(as.character(hf_records_dt$sex))

# Finally lets change numeric to integer for age
hf_records_dt$age = as.integer(hf_records_dt$age)

# Quick check of the data
hf_records_dt %>% summary
```

Though this isn't a lot of complex cleaning operations, the difference can be see in the summarization of the data. Now it is possible to get a preview and see how certain variables may have a relationship with the death indicator. As well those relationships can be explored further in a series of vizualizations.

```{r age_viz}
# Take a look at the possibility of a relationship between death an age
hf_records_agg = setNames(
  aggregate(anaemia ~ age + DEATH_EVENT, hf_records_dt, length),
  c("age", "DEATH_EVENT", "count"))
ggplot(hf_records_agg, aes(x=age, y=count, fill=DEATH_EVENT)) +
  geom_bar(position="stack", stat="identity")
```

The obvious thing to point out is that of course as people age they are more likely to die, but the question here is whether or not it would be to heart failure despite these treatements. With the results of the visualization, it can be seen that there is likely a relationship between age and the count of deaths. Something of note here is that all of the ages in the records don't commonly have deaths until close to the age of 60.

For other vizualizations it might be useful to utilize scatter plots with age and whatever other variables might be relevant.

```{r scatterplots}
# Going to scroll through a few of these numeric values and see if there are
#  any good clusters
ggplot(hf_records_dt, aes(x=age,y=creatinine_phosphokinase, color=DEATH_EVENT))+
  geom_point()

ggplot(hf_records_dt, aes(x=age, y=ejection_fraction, color=DEATH_EVENT)) +
  geom_point()

ggplot(hf_records_dt, aes(x=age, y=platelets, color=DEATH_EVENT)) +
  geom_point()

ggplot(hf_records_dt, aes(x=age, y=serum_creatinine, color=DEATH_EVENT)) +
  geom_point()

ggplot(hf_records_dt, aes(x=age, y=serum_sodium, color=DEATH_EVENT)) +
  geom_point()
```

This same age relation does seem to hold and there are some small indications for clustering with all the variables currently explored. However, it would be nice to make this clearer if it were possible to get more records allowing for denser and clearer clusters.

One of the variables that may not be as helpful is 'time' which according to the data source is the number of days before follow-up. All the others are possibly helpful for building model. During the modeling process multiple combinations, with the exception of the 'time' variable, will be used and tested. Main concern is that there aren't a lot of records, with only 299 available. The data will still be split out randomly for test data and validation but these will be fairly small, and there is the concern of overfitting. Having separate validation records should help diagnose if this does become an issue though.

Next milestone will include further exploration as models are created in oroder to find the most effective method of prediction.
